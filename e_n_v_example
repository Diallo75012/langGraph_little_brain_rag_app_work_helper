### ******************************************* MAIN .ENV FILE THAT IS NOT MUTABLE: HERE ARE THE SECRETS  *********************************************** ###

# IF USING LM Studio
LM_OPENAI_API_KEY="no_need_api_key_for_lmstudio"
LM_OPENAI_MODEL_NAME="<MODEL_NAME>"
LM_OPENAI_API_BASE="http://localhost:<PORT_DEFAULT_1234_OR_THE_ONE_YOU_HAVE_SET>/v1"

# IF USING GROQ API
GROQ_API_KEY="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"
MODEL_MIXTRAL_7B="mixtral-8x7b-32768"
MODEL_LLAMA3_8B="llama3-8b-8192"
MODEL_LLAMA3_70B="llama3-70b-8192"
#fine tuned models by groq for tool use
MODEL_LLAMA3_8B_TOOL_USE="llama3-groq-8b-8192-tool-use-preview"
MODEL_LLAMA3_70B_TOOL_USE="llama3-groq-70b-8192-tool-use-preview"
MODEL_GEMMA_7B="gemma-7b-it"
MODEL="mixtral-8x7b-32768"
# OPENAI_API_BASE_GROQ="https://api.groq.com/openai/v1"
GROQ_MAX_TOKEN=1024
GROQ_TEMPERATURE=0.1
GROQ_TEMPERATURE_CREATIVE=0.8

# EMBEDDINGS TEMPERATURE
EMBEDDINGS_TEMPERATURE=0.1

# IF USING OPENAI API
OPENAI_API_KEY="<YOUR_KEY>"
OPENAI_MODEL_NAME="<MODEL_NAME>"
OPENAI_API_BASE="https://api.openai.com/v1/chat/completions"
OPENAI_ORGANIZATION_ID="<YOUR_ORGANIZATION>"
OPENAI_PROJECT_ID="<YOUR_PROJECT_ID>"

# IF USING LANGFUSE: Monitoring LLM calls
LANG_SECRET_KEY="<SECRET>"
LANG_PUBLIC_KEY="<KEY>"
LANG_HOST="http://localhost:3000"
LANGFUSE_SECRET_KEY="SECRET"
LANGFUSE_PUBLIC_KEY="KEY"
LANGFUSE_HOST="http://localhost:3000"

# POSTGRESQL
# local postgresql db for app different from the one in docker for langfuse
DRIVER=psycopg2
HOST=0.0.0.0
PORT=5432
DATABASE=<DATABASE_NAME>
USER=<USER>
PASSWORD=<PASSWORD>
COLLECTION_NAME=<COLLECTION_NAME_FOR_PGVECTOR>
# GRAPH POSTGRESQL TABLE NAME USED: can be set here or in the .var.env config file
TABLE_NAME="<TABLE_NAME_FOR_GRAPH_AGENTS>"

# REDIS CACHE
REDIS_HOST="<localhost_OR_REMOTE_URL>"
REDIS_PORT="6379"
TTL=<SECONDS_FOR_CACHE_PERSISTENCE>


### ****************************** SECOND ENV FILE WHICH IS TH CONFIGS AND DYNAMIC ENV VARS  ************************************** ###
##### CONFIGS OF THE APP SET BY BUSINESS OWNER
# 200
MAXIMUM_CONTENT_LENGTH=<MAX_CONTENT_SUMMARIZATION_LENGTH>
# 30
MAXIMUM_TITLE_LENGTH=<MAX_TITLE_SUMMARIZATION_LENGTH>
# 250
CHUNK_SIZE_FOR_DB=<CHUNK_SIZE>
# 500
CHUNK_SIZE_FOR_EMBEDDINGS=<CHUNK_SIZE>
THREAD_ID=<NUMBER_TO_HAVE_GRAPH_BEING_ABLE_TO_STOP_AND_RESTART_THE_SAME_THREAD_SO_IT_REMEBERS_WHERE_IT_HAS_STOPPED>
TTL=<SECONDS_TTL_FOR_CACHE>
# to start then increase it accordingly depending on model used embedding vs llm model vs satisfaction of retrieved data 0.4
SCORE=<SIMILARITY SCORE>
# 2
TOP_N=<NUMBER_OF_RESULTS_RETRIEVED_WHILE_PERFORMING_SIMILIRITY_SEARCH>
EMBEDDINGS_TEMPERATURE=0
# report path
REPORT_PATH=<REPORT_PATH>.md

#### DYNAMIC ENV SET BY APP JUST UNDER HERE THAT ARE GONNA BE USED BY GRAPHS
QUERY_REFORMULATED=''
PARQUET_FILE_PATH=''
EMBEDDING_GRAPH_RESULT=''
REPORT_GRAPH_RESULT=''
